FINAL PROJECT
========================

1. Use retail_db from https://github.com/erkansirin78/datasets/tree/master/retail_db

2. Import all retail_db into mysql azhadoop database

3. Using sqoop import all tables into hive table 

4. Using apache spark find most cancelled 10 categories in total price

5. write results into hive table 



SOLUTION
=========================
1. connect sandbox with maria_dev, create retail_db directory and import all csv files

[maria_dev@sandbox-hdp ~]$ mkdir retail_db
[maria_dev@sandbox-hdp ~]$ cd retail_db/


[maria_dev@sandbox-hdp retail_db]$ wget https://raw.githubusercontent.com/erkansirin78/datasets/master/retail_db/categories.csv
[maria_dev@sandbox-hdp retail_db]$ wget https://raw.githubusercontent.com/erkansirin78/datasets/master/retail_db/customers.csv
[maria_dev@sandbox-hdp retail_db]$ wget https://raw.githubusercontent.com/erkansirin78/datasets/master/retail_db/departments.csv
[maria_dev@sandbox-hdp retail_db]$ wget https://raw.githubusercontent.com/erkansirin78/datasets/master/retail_db/order_items.csv
[maria_dev@sandbox-hdp retail_db]$ wget https://raw.githubusercontent.com/erkansirin78/datasets/master/retail_db/orders.csv
[maria_dev@sandbox-hdp retail_db]$ wget https://raw.githubusercontent.com/erkansirin78/datasets/master/retail_db/products.csv


2. connect mysql with root user 
[maria_dev@sandbox-hdp retail_db]$ mysql -u root -p
Enter password:hortonworks1

3. create azhadoop database
mysql> create database if not exists azhadoop;


4. grand privileges to root user on azhadoop 
mysql> GRANT ALL PRIVILEGES ON azhadoop.* TO 'root'@'localhost';
mysql> GRANT ALL PRIVILEGES ON azhadoop.* TO 'root'@'sandbox-hdp.hortonworks.com';

5. select azhadoop database 
use azhadoop;


5. Create mysql tables 
create table if not exists categories(categoryId int, categoryDepartmentId int, categoryName VARCHAR(50));
create table if not exists customers(customerId int, customerFName VARCHAR(50), customerLName VARCHAR(50), customerEmail VARCHAR(50), customerPassword VARCHAR(50), customerStreet VARCHAR(50), customerCity VARCHAR(50), customerState VARCHAR(5), customerZipcode VARCHAR(15));
create table if not exists departments(departmentId int, departmentName VARCHAR(20));
create table if not exists order_items(orderItemName int, orderItemOrderId int, orderItemProductId int, orderItemQuantity int, orderItemSubTotal double, orderItemProductPrice double);
create table if not exists orders(orderId int, orderDate VARCHAR(50), orderCustomerId int, orderStatus VARCHAR(20));
create table if not exists products(productId int, productCategoryId int, productName VARCHAR(255), productDescription VARCHAR(255), productPrice double, productImage VARCHAR(255));


6. load csv data into tables

LOAD DATA LOCAL INFILE '/home/maria_dev/retail_db/categories.csv' INTO TABLE categories
FIELDS TERMINATED BY ',' 
ENCLOSED BY '"' 
LINES TERMINATED BY '\n'
IGNORE 1 ROWS;

LOAD DATA LOCAL INFILE '/home/maria_dev/retail_db/customers.csv' INTO TABLE customers
FIELDS TERMINATED BY ',' 
ENCLOSED BY '"' 
LINES TERMINATED BY '\n'
IGNORE 1 ROWS;

LOAD DATA LOCAL INFILE '/home/maria_dev/retail_db/departments.csv' INTO TABLE departments
FIELDS TERMINATED BY ',' 
ENCLOSED BY '"' 
LINES TERMINATED BY '\n'
IGNORE 1 ROWS;

LOAD DATA LOCAL INFILE '/home/maria_dev/retail_db/order_items.csv' INTO TABLE order_items
FIELDS TERMINATED BY ',' 
ENCLOSED BY '"' 
LINES TERMINATED BY '\n'
IGNORE 1 ROWS;


LOAD DATA LOCAL INFILE '/home/maria_dev/retail_db/orders.csv' INTO TABLE orders
FIELDS TERMINATED BY ',' 
ENCLOSED BY '"' 
LINES TERMINATED BY '\n'
IGNORE 1 ROWS;


LOAD DATA LOCAL INFILE '/home/maria_dev/retail_db/products.csv' INTO TABLE products
FIELDS TERMINATED BY ',' 
ENCLOSED BY '"' 
LINES TERMINATED BY '\n'
IGNORE 1 ROWS;



7. check  loaded data
 select * from categories limit 5;
 select * from customers limit 5;
 select * from departments limit 5;
 select * from order_items limit 5;
 select * from orders limit 5;
 select * from products limit 5;
  

8. exit form mysql
\q 


9. Enter hive end create a database named azhadoop
[maria_dev@sandbox-hdp retail_db]$ hive
create database if not exists azhadoop;
quit;


10. add maria_dev user into hadoop group to prevent possible errors
sudo -i 
[root@sandbox-hdp ~]# usermod -a -G hadoop maria_dev

[root@sandbox-hdp ~]# su - maria_dev


11. import mysql tables into hive with sqoop

sqoop import --connect jdbc:mysql://sandbox-hdp.hortonworks.com/azhadoop \
--driver com.mysql.jdbc.Driver \
--username root --password hortonworks1 \
--query "select * from categories WHERE \$CONDITIONS" \
--m 1 --hive-import --create-hive-table \
--hive-table azhadoop.categories --target-dir /tmp/categories



sqoop import --connect jdbc:mysql://sandbox-hdp.hortonworks.com/azhadoop \
--driver com.mysql.jdbc.Driver \
--username root --password hortonworks1 \
--query "select * from customers WHERE \$CONDITIONS" \
--m 1 --hive-import --create-hive-table \
--hive-table azhadoop.customers --target-dir /tmp/customers



sqoop import --connect jdbc:mysql://sandbox-hdp.hortonworks.com/azhadoop \
--driver com.mysql.jdbc.Driver \
--username root --password hortonworks1 \
--query "select * from departments WHERE \$CONDITIONS" \
--m 1 --hive-import --create-hive-table \
--hive-table azhadoop.departments --target-dir /tmp/departments




sqoop import --connect jdbc:mysql://sandbox-hdp.hortonworks.com/azhadoop \
--driver com.mysql.jdbc.Driver \
--username root --password hortonworks1 \
--query "select * from order_items WHERE \$CONDITIONS" \
--m 1 --hive-import --create-hive-table \
--hive-table azhadoop.order_items --target-dir /tmp/order_items



sqoop import --connect jdbc:mysql://sandbox-hdp.hortonworks.com/azhadoop \
--driver com.mysql.jdbc.Driver \
--username root --password hortonworks1 \
--query "select * from orders WHERE \$CONDITIONS" \
--m 1 --hive-import --create-hive-table \
--hive-table azhadoop.orders --target-dir /tmp/orders


sqoop import --connect jdbc:mysql://sandbox-hdp.hortonworks.com/azhadoop \
--driver com.mysql.jdbc.Driver \
--username root --password hortonworks1 \
--query "select * from products WHERE \$CONDITIONS" \
--m 1 --hive-import --create-hive-table \
--hive-table azhadoop.products --target-dir /tmp/products

12. check hive tables
on hive shell 

select * from azhadoop.categories limit 5;
select * from azhadoop.customers limit 5;
select * from azhadoop.departments limit 5;
select * from azhadoop.order_items limit 5;
select * from azhadoop.orders limit 5;
select * from azhadoop.products limit 5;


13. Rest is in Spark IntelliJ Maven Project 
https://github.com/erkansirin78/hadoop-spark-for-developers/tree/master/final_project/SparkHive


Spark application computes and writes the results as hive table 

The results: most cancelled 10 categories.

SELECT * FROM most_cancelled_catg limit 10

categoryname        |total             |
--------------------|------------------|
Fishing             |134393.27999999965|
Cleats              | 85785.70000000006|
Cardio Equipment    | 81351.92999999996|
Camping & Hiking    |  80094.6600000001|
Water Sports        |  66196.6899999998|
Women's Apparel     |             65750|
Men's Footwear      | 60705.32999999974|
Indoor/Outdoor Games| 58126.74000000006|
Shop By Sport       |27423.440000000013|
Electronics         |            5685.5|
	 
	 
	 
	 
	 
	 
	 
	 
	 
	 
	 
	 