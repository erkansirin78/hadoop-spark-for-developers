NiFi Mysql’den Kafka’ya incremental veri akışı 
=====================================================


///////////////// 1. NIFI KURULUMU ///////////////////////////////////////////

NiFi kurulu ise bu adımı atlayınız
------------------------------------
root yetkisi ile 
1. nifi repo dosyasını /etc/yum.repos.d/ diznine indir.

cd /etc/yum.repos.d/
wget	http://public-repo-1.hortonworks.com/HDF/centos6/3.x/updates/3.1.2.0/hdf.repo
	
2. paket kontrolü
yum info nifi* 

3. Nifi indirme ve kurulumunu   1.3 GB (download esnasında mysql veri tabanı hazırlıkları yapılabilir)
yum -y install  nifi_3_1_2_0_7 

4. Nifi ayarlarından port numarasını değiştirelim çünkü 8080 dolu (Ambari)

vi /usr/hdf/current/nifi/conf/nifi.properties 
	
#web properties# bölümünde
nifi.web.http.port= değerini 8080'den 8090'a çek.

	
	
	Çalışırlık kontrolü:
/usr/hdf/current/nifi/bin/nifi.sh status
	
5. kurulum sonrası nifi çalıştırma
/usr/hdf/current/nifi/bin/nifi.sh start
	 
	 açılması biraz zaman alır bekleyiniz...
	 
6. Browser’a 

http://sandbox.hortonworks.com:8090/nifi/ 
	
	adresini gir ve NiFi arayüzünü gör. 


///////////////////// 2. MYSQL HAZIRLIKLAR ////////////////////////

maria_dev kullanıcısı ile 

 Mysql veri tabanında hazırlık yap.
 

1. Mysql’e bağlan, 
	azhadoop veri tabanı yoksa;
create database if not exists azhadoop;
	
use azhadoop; 

	
2. Tablo oluştur

mysql> create table iris_with_ts(Id INT NOT NULL AUTO_INCREMENT, SepalLengthCm DOUBLE, SepalWidthCm DOUBLE, PetalLengthCm DOUBLE, PetalWidthCm DOUBLE, Species VARCHAR(20), `UpdateTs` INT(11) NOT NULL, Status CHAR(1), PRIMARY KEY (Id));  
	
	komutuyla tablo yarat

3.
	
\q ile mysql'den çık.
	
	
	

///////////////////// 3. NIFI ARAYÜZ HAZIRLIKLAR ////////////////////////	
	
1.	Browser’a http://sandbox.hortonworks.com:8090/nifi/ adresini gir ve NiFi arayüzünü gör. 

2.	Nifi arayüzünden mysql veri tabanı bağlantısı için connection pool oluştur.
	 Ana sayfa -> sol menü configüration (küçük çark) -> controller service tabı -> sağ tarafta + işareti -> DBCPConnectionPool -> Add 
	 Eklendikten sonra satır sonundaki küçük çark ile  Configure
	 
	Properties tabına:
		Database connection url: jdbc:mysql://127.0.0.1/azhadoop
		Database Driver Class Name: com.mysql.jdbc.Driver
		Database Driver Location(s): /usr/share/java/mysql-connector-java.jar
		Database User: root
		Password: hortonworks1
		Validation query: SHOW TABLES;

3.		
Sağ taraftaki şimlşek ikonu ile enable et.
close
X 




///////////////////// 4. KAFKA HAZIRLIKLAR ////////////////////////	
 Kafka Topic Yaratma:
1. /usr/hdp/current/kafka-broker/bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic iris

2.	Kafka Producer:
/usr/hdp/current/kafka-broker/bin/kafka-console-producer.sh --broker-list sandbox-hdp.hortonworks.com:6667 --topic iris

3.	Kafka Consumer:
/usr/hdp/current/kafka-broker/bin/kafka-console-consumer.sh --bootstrap-server sandbox-hdp.hortonworks.com:6667 --topic iris --from-beginning

4.	Kafka Producer’dan örnek mesajlar yazarak çalışırlığını kontrol etme



///////////////////// 5. NIFI ARAYÜZÜNDE VERİ AKIŞI OLUŞTURMA ////////////////////////	


1. Nifi arayüzüne git

2. Yukarı menüden bir adet Process Group oluştur. (Sürükle bırak) İsmine MysqlToKafka verelim.


3. Çift tıklayıp içine girelim.

4. 1. Processor QueryDatabaseTable

Add Processor -> QueryDatabaseTable oluştur

5. Sağ tıkla -> Configure -> Properties sekmesi

	DatabaseConnectionPoolingService için yukarıda oluşturduğumuz connection poolu seçiyoruz.
	Database Type= Generic
	Table Name = iris_with_ts
	Columns to return = Hepsini seçmek istiyorsak boş kalıyor.
	Maximum-value columns = UpdateTs (incremental bir number olmalı)
	Geri kalan özellikler varsayılan
	

6. 2. processor ConvertAvroToJson
	QueryDatabaseTable Processoru'nü ConvertAvroToJson'a bağlıyoruz. 
	
	sağtıkla ve configure -> settings kısmından Automatically Terminate Relationship failure kutucuğunu seçiyoruz.
	
	
7. 3. processor PublishKafka_0_10 

ConvertAvroToJson PublishKafka_0_10 bağla success kutucuğunu işaretle

	Sağ tıkla configure 
	Settings tabından failure ve success kutucuklarını işaretle
	
	properties tabından 
	Kafka brokers = sandbox-hdp.hortonworks.com:6667
	topic name = iris
	

8. Tüm processorler üzerinde soluk kırmızı kare olmalıdır. Ünlem işareti varsa bazı ayarların eksik kaldığı anlamına gelir.
	
	


9. 	
Çalıştırma
sol alt köşeden ekmek kırıntısında Nifi Flow'a tıklayarak processorgroup sevyesine geçiniz.
sağ tıklayıp start deyin ve çift tıklayarak bir alt seviyeye tekrar geçiniz.


10. 
iris topiğini dinleyen Kafka-Console Consumer açık iken 
/usr/hdp/current/kafka-broker/bin/kafka-console-consumer.sh --bootstrap-server sandbox-hdp.hortonworks.com:6667 --topic iris --from-beginning
	
11. 
mysql veri tabanına bağlan ve aşağıdaki komutla veritabanına bilgi girmeye başlayınız.

use azhadoop;
insert into iris_with_ts(SepalLengthCm,SepalWidthCm,PetalLengthCm,PetalWidthCm,Species,UpdateTs, Status) values(4.0,4.0,4.0,4.0,'Iris-setosa', UNIX_TIMESTAMP(NOW()), 'I');
insert into iris_with_ts(SepalLengthCm,SepalWidthCm,PetalLengthCm,PetalWidthCm,Species,UpdateTs, Status) values(4.0,4.0,4.0,4.0,'Bu ikinci', UNIX_TIMESTAMP(NOW()), 'I');
insert into iris_with_ts(SepalLengthCm,SepalWidthCm,PetalLengthCm,PetalWidthCm,Species,UpdateTs, Status) values(4.0,4.0,4.0,4.0,'Bu üçüncü', UNIX_TIMESTAMP(NOW()), 'I');
UPDATE iris_with_ts SET Species='Updates', UpdateTs= UNIX_TIMESTAMP(NOW()), Status='U' WHERE Id=3;


12.
Kafka console consumer terminalinden sonuçları gözlemleyiniz:
{"Id": 1, "SepalLengthCm": 4.0, "SepalWidthCm": 4.0, "PetalLengthCm": 4.0, "PetalWidthCm": 4.0, "Species": "Iris-setosa", "UpdateTs": 1572292288, "Status": "I"}
{"Id": 2, "SepalLengthCm": 4.0, "SepalWidthCm": 4.0, "PetalLengthCm": 4.0, "PetalWidthCm": 4.0, "Species": "Bu ikinci", "UpdateTs": 1572292314, "Status": "I"}
{"Id": 3, "SepalLengthCm": 4.0, "SepalWidthCm": 4.0, "PetalLengthCm": 4.0, "PetalWidthCm": 4.0, "Species": "Bu üçüncü", "UpdateTs": 1572292327, "Status": "I"}
{"Id": 3, "SepalLengthCm": 4.0, "SepalWidthCm": 4.0, "PetalLengthCm": 4.0, "PetalWidthCm": 4.0, "Species": "Updates", "UpdateTs": 1572292350, "Status": "U"}




13. Arayüzden akışları durdur.
/usr/hdf/current/nifi/bin/nifi.sh stop


14. Kafka console consumer Ctrl+c ile durdurulur.
